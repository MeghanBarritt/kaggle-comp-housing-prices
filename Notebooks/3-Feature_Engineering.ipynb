{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "train = pd.read_pickle('../pickles/cleaned/train_cleaned')\n",
    "test = pd.read_pickle('../pickles/cleaned/test_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Mapping<p>\n",
    "In order to be used in regression, all columns need to be in a numberical format. Additionally, some columns can be combined into more meaningful data points, such as room counts.<p>\n",
    "First, heirarchical values, such as those ranging from 'poor' to 'excellent' can be converted into numerical ones quite easily, with 1 as the worst and counting up, using 0 where there is no data at all. <p>\n",
    "Some value schema are shared across multiple columns, and can all be mapped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 <- Ex\t(Excellent) <br>\n",
    "4 <- Gd\t(Good)<br>\n",
    "3 <- TA\t(Average/Typical)<br>\n",
    "2 <- Fa\t(Fair)<br>\n",
    "1 <- Po\t(Poor)<br>\n",
    "0 <- None\t(Doesn't have)<p>\n",
    "\n",
    "Columns this applies to:<p>\n",
    "`ExterQual`: Evaluates the quality of the material on the exterior<br>\n",
    "`ExterCond`: Evaluates the present condition of the material on the exterior<br>\n",
    "`BsmtQual`: Evaluates the height of the basement<br>\n",
    "`BsmtCond`: Evaluates the general condition of the basement<br>\n",
    "`HeatingQC`: Heating quality and condition<br>\n",
    "`KitchenQual`: Kitchen quality<br>\n",
    "`FireplaceQu`: Fireplace quality<br>\n",
    "`GarageQual`: Garage quality<br>\n",
    "`GarageCond`: Garage condition<br>\n",
    "`PoolQC`: Pool quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1 = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'PoolQC'] = train['PoolQC'].map(mapping1)\n",
    "train.loc[:, 'FireplaceQu'] = train['FireplaceQu'].map(mapping1)\n",
    "train.loc[:, 'GarageCond'] = train['GarageCond'].map(mapping1)\n",
    "train.loc[:, 'GarageQual'] = train['GarageQual'].map(mapping1)\n",
    "train.loc[:, 'KitchenQual'] = train['KitchenQual'].map(mapping1)\n",
    "train.loc[:, 'HeatingQC'] = train['HeatingQC'].map(mapping1)\n",
    "train.loc[:, 'BsmtCond'] = train['BsmtCond'].map(mapping1)\n",
    "train.loc[:, 'BsmtQual'] = train['BsmtQual'].map(mapping1)\n",
    "train.loc[:, 'ExterCond'] = train['ExterCond'].map(mapping1)\n",
    "train.loc[:, 'ExterQual'] = train['ExterQual'].map(mapping1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'PoolQC'] = test['PoolQC'].map(mapping1)\n",
    "test.loc[:, 'FireplaceQu'] = test['FireplaceQu'].map(mapping1)\n",
    "test.loc[:, 'GarageCond'] = test['GarageCond'].map(mapping1)\n",
    "test.loc[:, 'GarageQual'] = test['GarageQual'].map(mapping1)\n",
    "test.loc[:, 'KitchenQual'] = test['KitchenQual'].map(mapping1)\n",
    "test.loc[:, 'HeatingQC'] = test['HeatingQC'].map(mapping1)\n",
    "test.loc[:, 'BsmtCond'] = test['BsmtCond'].map(mapping1)\n",
    "test.loc[:, 'BsmtQual'] = test['BsmtQual'].map(mapping1)\n",
    "test.loc[:, 'ExterCond'] = test['ExterCond'].map(mapping1)\n",
    "test.loc[:, 'ExterQual'] = test['ExterQual'].map(mapping1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 <- GLQ (Good Living Quarters)<br>\n",
    "5 <- ALQ (Average Living Quarters)<br>\n",
    "4 <- BLQ (Below Average Living Quarters)\t<br>\n",
    "3 <- Rec (Average Rec Room)<br>\n",
    "2 <- LwQ (Low Quality)<br>\n",
    "1 <- Unf (Unfinshed)<br>\n",
    "0 <- None (Doesn't have)<p>\n",
    "\n",
    "Columes this applies to:<p>\n",
    "`BsmtFinType1`: Rating of basement finished area<br>\n",
    "`BsmtFinType2`: Rating of basement finished area (if multiple types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2 = {'GLQ':6, 'ALQ':5, 'BLQ':4, 'Rec':3, 'LwQ':2, 'Unf':1, 'None':0}\n",
    "\n",
    "train.loc[:, 'BsmtFinType1'] = train['BsmtFinType1'].map(mapping2)\n",
    "train.loc[:, 'BsmtFinType2'] = train['BsmtFinType2'].map(mapping2)\n",
    "\n",
    "test.loc[:, 'BsmtFinType1'] = test['BsmtFinType1'].map(mapping2)\n",
    "test.loc[:, 'BsmtFinType2'] = test['BsmtFinType2'].map(mapping2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 <- Grvl\t(Gravel)<br>\n",
    "1 <- Pave\t(Paved)<br>\n",
    "0 <- None (Only on `Alley`; no alley access)<p>\n",
    "\n",
    "Applies to:<p>\n",
    "`Street`: Type of road access to property<br>\n",
    "`Alley`: Type of alley access to property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping3 = {'Grvl':2, 'Pave':1, 'None':0}\n",
    "\n",
    "train.loc[:, 'Street'] = train['Street'].map(mapping3)\n",
    "train.loc[:, 'Alley'] = train['Alley'].map(mapping3)\n",
    "\n",
    "test.loc[:, 'Street'] = test['Street'].map(mapping3)\n",
    "test.loc[:, 'Alley'] = test['Alley'].map(mapping3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the columns all have unique value sets and must be mapped individually.<p><br></p>\n",
    "\n",
    "I'm going to convert the values for `LotShape` into numeric values, based on increasing irregularity. <p>\n",
    "1 <- Reg\t(Regular)<br>\n",
    "2 <- IR1\t(Slightly irregular)<br>\n",
    "3 <- IR2\t(Moderately Irregular)<br>\n",
    "4 <- IR3\t(Irregular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapemap = {'Reg':1, 'IR1':2, 'IR2':3, 'IR3':4}\n",
    "\n",
    "train.loc[:, 'LotShape'] = train['LotShape'].map(shapemap)\n",
    "\n",
    "test.loc[:, 'LotShape'] = test['LotShape'].map(shapemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am doing the same for the `LandSlope` column, increasing with severity.<p>\n",
    "1 <- Gtl\t(Gentle slope)<br>\n",
    "2 <- Mod\t(Moderate Slope)<br>\n",
    "3 <- Sev\t(Severe Slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopemap = {'Gtl':1, 'Mod':2, 'Sev':3}\n",
    "\n",
    "train.loc[:, 'LandSlope'] = train['LandSlope'].map(slopemap)\n",
    "\n",
    "test.loc[:, 'LandSlope'] = test['LandSlope'].map(slopemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the `LandContour` column imply an ordered heirarchy, and I am going to treat them as such.<p>\n",
    "\n",
    "4 <- Lvl\t(Near Flat/Level)<br>\n",
    "3 <- Bnk\t(Banked)<br>\n",
    "2 <- HLS\t(Hillside)<br>\n",
    "1 <- Low\t(Depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "contmap = {'Lvl':4,'Bnk':3,'HLS':2,'Low':1}\n",
    "\n",
    "train.loc[:, 'LandContour'] = train['LandContour'].map(contmap)\n",
    "\n",
    "test.loc[:, 'LandContour'] = test['LandContour'].map(contmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Utilities` column:<p>\n",
    "\n",
    "4 <- AllPub\t(All public Utilities)<br>\n",
    "3 <- NoSewr\t(Electricity, Gas, and Water (Septic Tank))<br>\n",
    "2 <- NoSeWa\t(Electricity and Gas Only)<br>\n",
    "1 <- ELO\t(Electricity only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilmap = {'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1}\n",
    "\n",
    "train.loc[:, 'Utilities'] = train['Utilities'].map(utilmap)\n",
    "\n",
    "test.loc[:, 'Utilities'] = test['Utilities'].map(utilmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the `LotConfig` column also impy an ordered heirarchy, with more street frontage being more desirable.<p>\n",
    "\n",
    "1 <- Inside\t(Inside lot)<br>\n",
    "2 <- Corner\t(Corner lot)<br>\n",
    "3 <- CulDSac\t(Cul-de-sac)<br>\n",
    "4 <- FR2\t(Frontage on 2 sides)<br>\n",
    "5 <- FR3\t(Frontage on 3 sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "configmap = {'Inside':1,'Corner':2,'CulDSac':3,'FR2':4,'FR3':5}\n",
    "\n",
    "train.loc[:, 'LotConfig'] = train['LotConfig'].map(configmap)\n",
    "\n",
    "test.loc[:, 'LotConfig'] = test['LotConfig'].map(configmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BsmtExposure` column:<p>\n",
    "\n",
    "4 <- Gd\t(Good Exposure)<br>\n",
    "3 <- Av\t(Average Exposure)<br>\n",
    "2 <- Mn\t(Mimimum Exposure)<br>\n",
    "1 <- No\t(No Exposure)<br>\n",
    "0 <- None\t(No Basement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmtmap = {'Gd':4, 'Av':3, 'Mn':2, 'No':1, 'None':0}\n",
    "\n",
    "train.loc[:, 'BsmtExposure'] = train['BsmtExposure'].map(bsmtmap)\n",
    "\n",
    "test.loc[:, 'BsmtExposure'] = test['BsmtExposure'].map(bsmtmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Functional` column:<p>\n",
    "\n",
    "8 <- Typ\t(Typical Functionality)<br>\n",
    "7 <- Min1\t(Minor Deductions 1)<br>\n",
    "6 <- Min2\t(Minor Deductions 2)<br>\n",
    "5 <- Mod\t(Moderate Deductions)<br>\n",
    "4 <- Maj1\t(Major Deductions 1)<br>\n",
    "3 <- Maj2\t(Major Deductions 2)<br>\n",
    "2 <- Sev\t(Severely Damaged)<br>\n",
    "1 <- Sal\t(Salvage only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "functmap = {'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}\n",
    "\n",
    "train.loc[:, 'Functional'] = train['Functional'].map(functmap)\n",
    "\n",
    "test.loc[:, 'Functional'] = test['Functional'].map(functmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GarageFinish` column:<p>\n",
    "\n",
    "3 <- Fin (Finished)<br>\n",
    "2 <- RFn (Rough Finished)<br>\n",
    "1 <- Unf (Unfinished)<br>\n",
    "0 <- None (No Garage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "garagemap = {'Fin':3, 'RFn':2, 'Unf':1, 'None':0}\n",
    "\n",
    "train.loc[:, 'GarageFinish'] = train['GarageFinish'].map(garagemap)\n",
    "\n",
    "test.loc[:, 'GarageFinish'] = test['GarageFinish'].map(garagemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PavedDrive` column:<p>\n",
    "3 <- Y\t(Paved) <br>\n",
    "2 <- P\t(Partial Pavement)<br>\n",
    "1 <- N\t(Dirt/Gravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavemap = {'Y':3, 'P':2, 'N':1}\n",
    "\n",
    "train.loc[:, 'PavedDrive'] = train['PavedDrive'].map(pavemap)\n",
    "\n",
    "test.loc[:, 'PavedDrive'] = test['PavedDrive'].map(pavemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Fence` column contains values which look like they could be contrasting pairs, but because they are all in the same column, they can't be treated that way. As such, I think the best way to treat them is to assume they are meant to be heirarchical.<p>\n",
    "4 <- GdPrv\t(Good Privacy)<br>\n",
    "3 <- MnPrv\t(Minimum Privacy)<br>\n",
    "2 <- GdWo\t(Good Wood)<br>\n",
    "1 <- MnWw\t(Minimum Wood/Wire)<br>\n",
    "0 <- None\t(No Fence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "fencemap = {\n",
    "'GdPrv':4,'MnPrv':3,'GdWo':2,'MnWw':1,'None':0\n",
    "}\n",
    "\n",
    "train.loc[:, 'Fence'] = train['Fence'].map(fencemap)\n",
    "\n",
    "test.loc[:, 'Fence'] = test['Fence'].map(fencemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the `CentralAir` column currently contains Yes/No values, and as such can be re-mapped using the standard 1/0 schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "airmap = {'Y':1, 'N':0}\n",
    "\n",
    "train.loc[:, 'CentralAir'] = train['CentralAir'].map(airmap)\n",
    "\n",
    "test.loc[:, 'CentralAir'] = test['CentralAir'].map(airmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding<p>\n",
    "Features that aren't numerical and have no obvious heirarchy need to be handled via One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some column pairs that share the same possible values. In order to capture both columns' data for each pair, I'm expanding both of them and then combing them into a single column set, with a max of two points across them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Condition1` and `Condition2` share the following value set:<p>\n",
    "\n",
    "Artery - Adjacent to arterial street<br>\n",
    "Feedr - Adjacent to feeder street<br>\n",
    "Norm - Normal\t<br>\n",
    "RRNn - Within 200' of North-South Railroad<br>\n",
    "RRAn - Adjacent to North-South Railroad<br>\n",
    "PosN - Near positive off-site feature--park, greenbelt, etc.<br>\n",
    "PosA - Adjacent to postive off-site feature<br>\n",
    "RRNe - Within 200' of East-West Railroad<br>\n",
    "RRAe - Adjacent to East-West Railroad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand both columns and combine for coalation\n",
    "train_c1 = pd.DataFrame(data=(enc.fit_transform(train[['Condition1']])),columns=(enc.get_feature_names_out()))\n",
    "train_c2 = pd.DataFrame(data=(enc.fit_transform(train[['Condition2']])),columns=(enc.get_feature_names_out()))\n",
    "train_condition = pd.concat([train_c1,train_c2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns that did not appear in the second set of conditions\n",
    "train_condition = train_condition.rename(columns={'Condition1_RRAe':'Cond_RRAe','Condition1_RRNe':'Cond_RRNe'})\n",
    "\n",
    "# create columns for coalating values \n",
    "train_condition['Cond_Artery'] = 0.0\n",
    "train_condition['Cond_Feedr'] = 0.0\n",
    "train_condition['Cond_Norm'] = 0.0\n",
    "train_condition['Cond_PosA'] = 0.0\n",
    "train_condition['Cond_PosN'] = 0.0\n",
    "train_condition['Cond_RRAn'] = 0.0\n",
    "train_condition['Cond_RRNn'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where either 'Artery' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_Artery']==1)| \n",
    "    (train_condition['Condition2_Artery']==1)\n",
    "].index).tolist()), 'Cond_Artery'] = 1\n",
    "\n",
    "# where either 'Feedr' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_Feedr']==1)|\n",
    "    (train_condition['Condition2_Feedr']==1)\n",
    "].index).tolist()), 'Cond_Feedr'] = 1\n",
    "\n",
    "# where either 'Norm' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_Norm']==1)|\n",
    "    (train_condition['Condition2_Norm']==1)\n",
    "].index).tolist()), 'Cond_Norm'] = 1\n",
    "\n",
    "# where either 'PosA' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_PosA']==1)|\n",
    "    (train_condition['Condition2_PosA']==1)\n",
    "].index).tolist()), 'Cond_PosA'] = 1\n",
    "\n",
    "# where either 'PosN' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_PosN']==1)|\n",
    "    (train_condition['Condition2_PosN']==1)\n",
    "].index).tolist()), 'Cond_PosN'] = 1\n",
    "\n",
    "# where either 'RRAn' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_RRAn']==1)|\n",
    "    (train_condition['Condition2_RRAn']==1)\n",
    "].index).tolist()), 'Cond_RRAn'] = 1\n",
    "\n",
    "# where either 'RRNn' expansion is 1, fill master column with a 1\n",
    "train_condition.loc[((train_condition[\n",
    "    (train_condition['Condition1_RRNn']==1)|\n",
    "    (train_condition['Condition2_RRNn']==1)\n",
    "].index).tolist()), 'Cond_RRNn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the columns to keep back onto main dataframe\n",
    "train = pd.concat([train.reset_index(),train_condition[['Cond_Artery','Cond_Feedr','Cond_Norm','Cond_RRNn','Cond_RRAn',\n",
    "                                                        'Cond_PosN','Cond_PosA','Cond_RRNe','Cond_RRAe']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand both columns and combine for coalation\n",
    "test_c1 = pd.DataFrame(data=(enc.fit_transform(test[['Condition1']])),columns=(enc.get_feature_names_out()))\n",
    "test_c2 = pd.DataFrame(data=(enc.fit_transform(test[['Condition2']])),columns=(enc.get_feature_names_out()))\n",
    "test_condition = pd.concat([test_c1,test_c2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns that did not appear in the second set of conditions\n",
    "test_condition = test_condition.rename(columns={'Condition1_RRAe':'Cond_RRAe','Condition1_RRAn':'Cond_RRAn','Condition1_RRNe':'Cond_RRNe','Condition1_RRNn':'Cond_RRNn'})\n",
    "\n",
    "# create columns for coalating values \n",
    "test_condition['Cond_Artery'] = 0.0\n",
    "test_condition['Cond_Feedr'] = 0.0\n",
    "test_condition['Cond_Norm'] = 0.0\n",
    "test_condition['Cond_PosA'] = 0.0\n",
    "test_condition['Cond_PosN'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where either 'Artery' expansion is 1, fill master column with a 1\n",
    "test_condition.loc[((test_condition[\n",
    "    (test_condition['Condition1_Artery']==1)|\n",
    "    (test_condition['Condition2_Artery']==1)\n",
    "].index).tolist()), 'Cond_Artery'] = 1\n",
    "\n",
    "# where either 'Feedr' expansion is 1, fill master column with a 1\n",
    "test_condition.loc[((test_condition[\n",
    "    (test_condition['Condition1_Feedr']==1)|\n",
    "    (test_condition['Condition2_Feedr']==1)\n",
    "].index).tolist()), 'Cond_Feedr'] = 1\n",
    "\n",
    "# where either 'Norm' expansion is 1, fill master column with a 1\n",
    "test_condition.loc[((test_condition[\n",
    "    (test_condition['Condition1_Norm']==1)|\n",
    "    (test_condition['Condition2_Norm']==1)\n",
    "].index).tolist()), 'Cond_Norm'] = 1\n",
    "\n",
    "# where either 'PosA' expansion is 1, fill master column with a 1\n",
    "test_condition.loc[((test_condition[\n",
    "    (test_condition['Condition1_PosA']==1)|\n",
    "    (test_condition['Condition2_PosA']==1)\n",
    "].index).tolist()), 'Cond_PosA'] = 1\n",
    "\n",
    "# where either 'PosN' expansion is 1, fill master column with a 1\n",
    "test_condition.loc[((test_condition[\n",
    "    (test_condition['Condition1_PosN']==1)|\n",
    "    (test_condition['Condition2_PosN']==1)\n",
    "].index).tolist()), 'Cond_PosN'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the columns to keep back onto main dataframe\n",
    "test = pd.concat([test.reset_index(),test_condition[['Cond_Artery','Cond_Feedr','Cond_Norm','Cond_RRNn','Cond_RRAn',\n",
    "                                                        'Cond_PosN','Cond_PosA','Cond_RRNe','Cond_RRAe']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exterior1st` and `Exterior2nd` share the following set of possible values:<p>\n",
    "\n",
    "AsbShng - Asbestos Shingles<br>\n",
    "AsphShn - Asphalt Shingles<br>\n",
    "BrkComm - Brick Common<br>\n",
    "BrkFace - Brick Face<br>\n",
    "CBlock - Cinder Block<br>\n",
    "CemntBd - Cement Board<br>\n",
    "HdBoard - Hard Board<br>\n",
    "ImStucc - Imitation Stucco<br>\n",
    "MetalSd - Metal Siding<br>\n",
    "Other - Other<br>\n",
    "Plywood - Plywood<br>\n",
    "PreCast - PreCast<br>\n",
    "Stone  -Stone<br>\n",
    "Stucco - Stucco<br>\n",
    "VinylSd - Vinyl Siding<br>\n",
    "Wd Sdng - Wood Siding<br>\n",
    "WdShing - Wood Shingles<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ext1 = pd.DataFrame(data=(enc.fit_transform(train[['Exterior1st']])),columns=(enc.get_feature_names_out()))\n",
    "train_ext2 = pd.DataFrame(data=(enc.fit_transform(train[['Exterior2nd']])),columns=(enc.get_feature_names_out()))\n",
    "train_exterior = pd.concat([train_ext1,train_ext2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column that only appears in one dataframe\n",
    "train_exterior = train_exterior.rename(columns={'Exterior2nd_Other':'Ext_Other'})\n",
    "\n",
    "# create columns for coalating values\n",
    "train_exterior['Ext_AsbShng'] = 0.0\n",
    "train_exterior['Ext_AsphShn'] = 0.0\n",
    "train_exterior['Ext_BrkComm'] = 0.0\n",
    "train_exterior['Ext_BrkFace'] = 0.0\n",
    "train_exterior['Ext_CBlock'] = 0.0\n",
    "train_exterior['Ext_CemntBd'] = 0.0\n",
    "train_exterior['Ext_HdBoard'] = 0.0\n",
    "train_exterior['Ext_ImStucc'] = 0.0\n",
    "train_exterior['Ext_MetalSd'] = 0.0\n",
    "train_exterior['Ext_Plywood'] = 0.0\n",
    "train_exterior['Ext_Stone'] = 0.0\n",
    "train_exterior['Ext_Stucco'] = 0.0\n",
    "train_exterior['Ext_VinylSd'] = 0.0\n",
    "train_exterior['Ext_Wd_Sdng'] = 0.0\n",
    "train_exterior['Ext_WdShing'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where either 'AsbShng' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_AsbShng']==1)|\n",
    "    (train_exterior['Exterior2nd_AsbShng']==1)\n",
    "].index).tolist()), 'Ext_AsbShng'] = 1\n",
    "\n",
    "# where either 'AsphShn' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_AsphShn']==1)|\n",
    "    (train_exterior['Exterior2nd_AsphShn']==1)\n",
    "].index).tolist()), 'Ext_AsphShn'] = 1\n",
    "\n",
    "# where either 'BrkComm' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_BrkComm']==1)|\n",
    "    (train_exterior['Exterior2nd_Brk Cmn']==1)\n",
    "].index).tolist()), 'Ext_BrkComm'] = 1\n",
    "\n",
    "# where either 'BrkFace' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_BrkFace']==1)|\n",
    "    (train_exterior['Exterior2nd_BrkFace']==1)\n",
    "].index).tolist()), 'Ext_BrkFace'] = 1\n",
    "\n",
    "# where either 'CBlock' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_CBlock']==1)|\n",
    "    (train_exterior['Exterior2nd_CBlock']==1)\n",
    "].index).tolist()), 'Ext_CBlock'] = 1\n",
    "\n",
    "# where either 'CemntBd' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_CemntBd']==1)|\n",
    "    (train_exterior['Exterior2nd_CmentBd']==1)\n",
    "].index).tolist()), 'Ext_CemntBd'] = 1\n",
    "\n",
    "# where either 'HdBoard' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_HdBoard']==1)|\n",
    "    (train_exterior['Exterior2nd_HdBoard']==1)\n",
    "].index).tolist()), 'Ext_HdBoard'] = 1\n",
    "\n",
    "# where either 'ImStucc' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_ImStucc']==1)|\n",
    "    (train_exterior['Exterior2nd_ImStucc']==1)\n",
    "].index).tolist()), 'Ext_ImStucc'] = 1\n",
    "\n",
    "# where either 'MetalSd' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_MetalSd']==1)|\n",
    "    (train_exterior['Exterior2nd_MetalSd']==1)\n",
    "].index).tolist()), 'Ext_MetalSd'] = 1\n",
    "\n",
    "# where either 'Plywood' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_Plywood']==1)|\n",
    "    (train_exterior['Exterior2nd_Plywood']==1)\n",
    "].index).tolist()), 'Ext_Plywood'] = 1\n",
    "\n",
    "# where either 'Stone' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_Stone']==1)|\n",
    "    (train_exterior['Exterior2nd_Stone']==1)\n",
    "].index).tolist()), 'Ext_Stone'] = 1\n",
    "\n",
    "# where either 'Stucco' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_Stucco']==1)|\n",
    "    (train_exterior['Exterior2nd_Stucco']==1)\n",
    "].index).tolist()), 'Ext_Stucco'] = 1\n",
    "\n",
    "# where either 'VinylSd' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_VinylSd']==1)|\n",
    "    (train_exterior['Exterior2nd_VinylSd']==1)\n",
    "].index).tolist()), 'Ext_VinylSd'] = 1\n",
    "\n",
    "# where either 'Wd Sdng' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_Wd Sdng']==1)|\n",
    "    (train_exterior['Exterior2nd_Wd Shng']==1)\n",
    "].index).tolist()), 'Ext_Wd_Sdng'] = 1\n",
    "\n",
    "# where either 'WdShing' expansion is 1, fill master column with a 1\n",
    "train_exterior.loc[((train_exterior[\n",
    "    (train_exterior['Exterior1st_WdShing']==1)|\n",
    "    (train_exterior['Exterior2nd_Wd Sdng']==1)\n",
    "].index).tolist()), 'Ext_WdShing'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the columns to keep back onto main dataframe\n",
    "train = pd.concat([train,train_exterior[['Ext_AsbShng','Ext_AsphShn','Ext_BrkComm','Ext_BrkFace','Ext_CBlock','Ext_CemntBd','Ext_HdBoard','Ext_ImStucc',\n",
    "'Ext_MetalSd','Ext_Other','Ext_Plywood','Ext_Stone','Ext_Stucco','Ext_VinylSd','Ext_Wd_Sdng','Ext_WdShing']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ext1 = pd.DataFrame(data=(enc.fit_transform(test[['Exterior1st']])),columns=(enc.get_feature_names_out()))\n",
    "test_ext2 = pd.DataFrame(data=(enc.fit_transform(test[['Exterior2nd']])),columns=(enc.get_feature_names_out()))\n",
    "test_exterior = pd.concat([test_ext1,test_ext2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns that only appear in one dataframe\n",
    "test_exterior = test_exterior.rename(columns={'Exterior2nd_ImStucc':'Ext_ImStucc','Exterior2nd_Stone':'Ext_Stone'})\n",
    "\n",
    "# create columns for coalating values\n",
    "test_exterior['Ext_AsbShng'] = 0.0\n",
    "test_exterior['Ext_AsphShn'] = 0.0\n",
    "test_exterior['Ext_BrkComm'] = 0.0\n",
    "test_exterior['Ext_BrkFace'] = 0.0\n",
    "test_exterior['Ext_CBlock'] = 0.0\n",
    "test_exterior['Ext_CemntBd'] = 0.0\n",
    "test_exterior['Ext_HdBoard'] = 0.0\n",
    "test_exterior['Ext_MetalSd'] = 0.0\n",
    "test_exterior['Ext_Other'] = 0.0\n",
    "test_exterior['Ext_Plywood'] = 0.0\n",
    "test_exterior['Ext_Stucco'] = 0.0\n",
    "test_exterior['Ext_VinylSd'] = 0.0\n",
    "test_exterior['Ext_Wd_Sdng'] = 0.0\n",
    "test_exterior['Ext_WdShing'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where either 'AsbShng' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_AsbShng']==1)|\n",
    "    (test_exterior['Exterior2nd_AsbShng']==1)\n",
    "].index).tolist()), 'Ext_AsbShng'] = 1\n",
    "\n",
    "# where either 'AsphShn' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_AsphShn']==1)|\n",
    "    (test_exterior['Exterior2nd_AsphShn']==1)\n",
    "].index).tolist()), 'Ext_AsphShn'] = 1\n",
    "\n",
    "# where either 'BrkComm' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_BrkComm']==1)|\n",
    "    (test_exterior['Exterior2nd_Brk Cmn']==1)\n",
    "].index).tolist()), 'Ext_BrkComm'] = 1\n",
    "\n",
    "# where either 'BrkFace' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_BrkFace']==1)|\n",
    "    (test_exterior['Exterior2nd_BrkFace']==1)\n",
    "].index).tolist()), 'Ext_BrkFace'] = 1\n",
    "\n",
    "# where either 'CBlock' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_CBlock']==1)|\n",
    "    (test_exterior['Exterior2nd_CBlock']==1)\n",
    "].index).tolist()), 'Ext_CBlock'] = 1\n",
    "\n",
    "# where either 'CemntBd' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_CemntBd']==1)|\n",
    "    (test_exterior['Exterior2nd_CmentBd']==1)\n",
    "].index).tolist()), 'Ext_CemntBd'] = 1\n",
    "\n",
    "# where either 'HdBoard' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_HdBoard']==1)|\n",
    "    (test_exterior['Exterior2nd_HdBoard']==1)\n",
    "].index).tolist()), 'Ext_HdBoard'] = 1\n",
    "\n",
    "# where either 'MetalSd' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_MetalSd']==1)|\n",
    "    (test_exterior['Exterior2nd_MetalSd']==1)\n",
    "].index).tolist()), 'Ext_MetalSd'] = 1\n",
    "\n",
    "# where either 'Other' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_Other']==1)|\n",
    "    (test_exterior['Exterior2nd_Other']==1)\n",
    "].index).tolist()), 'Ext_Other'] = 1\n",
    "\n",
    "# where either 'Plywood' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_Plywood']==1)|\n",
    "    (test_exterior['Exterior2nd_Plywood']==1)\n",
    "].index).tolist()), 'Ext_Plywood'] = 1\n",
    "\n",
    "# where either 'Stucco' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_Stucco']==1)|\n",
    "    (test_exterior['Exterior2nd_Stucco']==1)\n",
    "].index).tolist()), 'Ext_Stucco'] = 1\n",
    "\n",
    "# where either 'VinylSd' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_VinylSd']==1)|\n",
    "    (test_exterior['Exterior2nd_VinylSd']==1)\n",
    "].index).tolist()), 'Ext_VinylSd'] = 1\n",
    "\n",
    "# where either 'Wd Sdng' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_Wd Sdng']==1)|\n",
    "    (test_exterior['Exterior2nd_Wd Shng']==1)\n",
    "].index).tolist()), 'Ext_Wd_Sdng'] = 1\n",
    "\n",
    "# where either 'WdShing' expansion is 1, fill master column with a 1\n",
    "test_exterior.loc[((test_exterior[\n",
    "    (test_exterior['Exterior1st_WdShing']==1)|\n",
    "    (test_exterior['Exterior2nd_Wd Sdng']==1)\n",
    "].index).tolist()), 'Ext_WdShing'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the columns to keep back onto main dataframe\n",
    "test = pd.concat([test,test_exterior[['Ext_AsbShng','Ext_AsphShn','Ext_BrkComm','Ext_BrkFace','Ext_CBlock','Ext_CemntBd','Ext_HdBoard','Ext_ImStucc',\n",
    "'Ext_MetalSd','Ext_Other','Ext_Plywood','Ext_Stone','Ext_Stucco','Ext_VinylSd','Ext_Wd_Sdng','Ext_WdShing']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the remaining columns share values, so they can't be combined into during expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MSZoning` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zone = pd.DataFrame(data=(enc.fit_transform(train[['MSZoning']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# simplifying name of 'C (all)' column to just 'C'\n",
    "train_zone = train_zone.rename(columns={'MSZoning_C (all)':'MSZoning_C'})\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_zone],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zone = pd.DataFrame(data=(enc.fit_transform(test[['MSZoning']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# simplifying name of 'C (all)' column to just 'C'\n",
    "test_zone = test_zone.rename(columns={'MSZoning_C (all)':'MSZoning_C'})\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_zone],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Neighborhood` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nbhd = pd.DataFrame(data=(enc.fit_transform(train[['Neighborhood']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_nbhd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nbhd = pd.DataFrame(data=(enc.fit_transform(test[['Neighborhood']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_nbhd],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BldgType` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = pd.DataFrame(data=(enc.fit_transform(train[['BldgType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_type],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type = pd.DataFrame(data=(enc.fit_transform(test[['BldgType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_type],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HouseStyle` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_style = pd.DataFrame(data=(enc.fit_transform(train[['HouseStyle']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_style],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_style = pd.DataFrame(data=(enc.fit_transform(test[['HouseStyle']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_style],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RoofStyle` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_RfStyl = pd.DataFrame(data=(enc.fit_transform(train[['RoofStyle']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_RfStyl],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RfStyl = pd.DataFrame(data=(enc.fit_transform(test[['RoofStyle']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_RfStyl],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RoofMatl` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_RfMat = pd.DataFrame(data=(enc.fit_transform(train[['RoofMatl']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_RfMat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_RfMat = pd.DataFrame(data=(enc.fit_transform(test[['RoofMatl']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# create columns for options present in train but missing in test\n",
    "test_RfMat['RoofMatl_Membran'] = 0.0\n",
    "test_RfMat['RoofMatl_Metal'] = 0.0\n",
    "test_RfMat['RoofMatl_Roll'] = 0.0\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_RfMat],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MasVnrType` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vnr = pd.DataFrame(data=(enc.fit_transform(train[['MasVnrType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_vnr],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vnr = pd.DataFrame(data=(enc.fit_transform(test[['MasVnrType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_vnr],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Foundation` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_found = pd.DataFrame(data=(enc.fit_transform(train[['Foundation']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_found],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_found = pd.DataFrame(data=(enc.fit_transform(test[['Foundation']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_found],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Heating` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heat = pd.DataFrame(data=(enc.fit_transform(train[['Heating']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_heat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_heat = pd.DataFrame(data=(enc.fit_transform(test[['Heating']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# create columns for options present in train but missing in test\n",
    "test_heat['Heating_Floor'] = 0.0\n",
    "test_heat['Heating_OthW'] = 0.0\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_heat],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Electrical` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elec = pd.DataFrame(data=(enc.fit_transform(train[['Electrical']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_elec],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_elec = pd.DataFrame(data=(enc.fit_transform(test[['Electrical']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# create column for option present in train but missing in test\n",
    "test_elec['Electrical_Mix'] = 0.0\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_elec],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GarageType` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_garage = pd.DataFrame(data=(enc.fit_transform(train[['GarageType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# drop none column\n",
    "train_garage = train_garage.drop('GarageType_None',axis=1)\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_garage],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_garage = pd.DataFrame(data=(enc.fit_transform(test[['GarageType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# drop none column\n",
    "test_garage = test_garage.drop('GarageType_None',axis=1)\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_garage],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MiscFeature` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_misc = pd.DataFrame(data=(enc.fit_transform(train[['MiscFeature']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# create column for option present in test but missing in train\n",
    "train_misc['MiscFeature_Gar2'] = 0.0\n",
    "\n",
    "# drop nan column\n",
    "train_misc = train_misc.drop('MiscFeature_nan',axis=1)\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_misc],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_misc = pd.DataFrame(data=(enc.fit_transform(test[['MiscFeature']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# create column for option present in train but missing in test\n",
    "test_misc['MiscFeature_TenC'] = 0.0\n",
    "\n",
    "# drop nan column\n",
    "test_misc = test_misc.drop('MiscFeature_nan',axis=1)\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_misc],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiscFeature\n",
       "Shed    47\n",
       "Othr     2\n",
       "TenC     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['MiscFeature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiscFeature\n",
       "Shed    46\n",
       "Gar2     3\n",
       "Othr     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['MiscFeature'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SaleType` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SType = pd.DataFrame(data=(enc.fit_transform(train[['SaleType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_SType],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SType = pd.DataFrame(data=(enc.fit_transform(test[['SaleType']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_SType],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SaleCondition` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SCond = pd.DataFrame(data=(enc.fit_transform(train[['SaleCondition']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "train = pd.concat([train,train_SCond],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SCond = pd.DataFrame(data=(enc.fit_transform(test[['SaleCondition']])),columns=(enc.get_feature_names_out()))\n",
    "\n",
    "# merge new columns back into main dataframe\n",
    "test = pd.concat([test,test_SCond],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist = [\n",
    "    'index','Condition1','Condition2','Exterior1st','Exterior2nd',\n",
    "    'Foundation','Heating','HouseStyle'\n",
    "    'Electrical','RoofStyle','RoofMatl',\n",
    "    'MasVnrType','MSZoning','BldgType',\n",
    "    'Neighborhood','GarageType','MiscFeature','SaleType', 'SaleCondition'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining and Creating Columns<p>\n",
    "The total living space for each property can be calculated using the `GrLivArea` column, for the area above ground level, and the `TotalBsmtSF1` column, for the area of the basement, if one exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TtlLivSF'] = train['GrLivArea']+train['TotalBsmtSF']\n",
    "test['TtlLivSF'] = test['GrLivArea']+test['TotalBsmtSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>TtlLivSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>856</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>920</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>756</td>\n",
       "      <td>2473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>1145</td>\n",
       "      <td>3343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  TotalBsmtSF  TtlLivSF\n",
       "0       1710          856      2566\n",
       "1       1262         1262      2524\n",
       "2       1786          920      2706\n",
       "3       1717          756      2473\n",
       "4       2198         1145      3343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>TtlLivSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>882.0</td>\n",
       "      <td>1778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>2658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1629</td>\n",
       "      <td>928.0</td>\n",
       "      <td>2557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1604</td>\n",
       "      <td>926.0</td>\n",
       "      <td>2530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>2560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  TotalBsmtSF  TtlLivSF\n",
       "0        896        882.0    1778.0\n",
       "1       1329       1329.0    2658.0\n",
       "2       1629        928.0    2557.0\n",
       "3       1604        926.0    2530.0\n",
       "4       1280       1280.0    2560.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Train head:')\n",
    "display(train[['GrLivArea', 'TotalBsmtSF', 'TtlLivSF']].head())\n",
    "print('Test head:')\n",
    "display(test[['GrLivArea', 'TotalBsmtSF', 'TtlLivSF']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of bathrooms can also be calculated using the four columns tracking number of bathrooms. (Halfbath columns are multiplied by 0.5 to reflect that they are 'half' when being added to the count.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TotalBath'] = train['BsmtFullBath']+(train['BsmtHalfBath']*0.5)+train['FullBath']+(train['HalfBath']*0.5)\n",
    "test['TotalBath'] = test['BsmtFullBath']+(test['BsmtHalfBath']*0.5)+test['FullBath']+(test['HalfBath']*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>TotalBath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  TotalBath\n",
       "0             1             0         2         1        3.5\n",
       "1             0             1         2         0        2.5\n",
       "2             1             0         2         1        3.5\n",
       "3             1             0         1         0        2.0\n",
       "4             1             0         2         1        3.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>TotalBath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  TotalBath\n",
       "0           0.0           0.0         1         0        1.0\n",
       "1           0.0           0.0         1         1        1.5\n",
       "2           0.0           0.0         2         1        2.5\n",
       "3           0.0           0.0         2         1        2.5\n",
       "4           0.0           0.0         2         0        2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Train head:')\n",
    "display(train[['BsmtFullBath', 'BsmtHalfBath', 'FullBath','HalfBath', 'TotalBath']].head())\n",
    "print('Test head:')\n",
    "display(test[['BsmtFullBath', 'BsmtHalfBath', 'FullBath','HalfBath', 'TotalBath']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the `HouseStyle` references to the number of stories only reflect the ones above ground, I am going to make a column for the total number of floors, using the columns that record the total area for basement, first and second floor. There is no column for area of the third story, in the cases of a property being marked as 2.5 stories. There are no cases of properties in the 2.5 category that have no basement, so I don't need to worry about that and can encode them all has having 4 total floors. <p>\n",
    "I am going to create the new column with a value of 0 so I can check that all the columns have been encoded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column \n",
    "train['TtlFloors'] = 0\n",
    "\n",
    "# encode the applicable values\n",
    "# only a ground floor\n",
    "train.loc[((train[(train['1stFlrSF']>0)&(train['TotalBsmtSF']==0)&(train['2ndFlrSF']==0)\n",
    "].index).tolist()), 'TtlFloors'] = 1\n",
    "\n",
    "# ground floor and basement\n",
    "train.loc[((train[(train['1stFlrSF']>0)&(train['TotalBsmtSF']>0)&(train['2ndFlrSF']==0)\n",
    "].index).tolist()), 'TtlFloors'] = 2\n",
    "\n",
    "# ground floor and second floor\n",
    "train.loc[((train[(train['1stFlrSF']>0)&(train['TotalBsmtSF']==0)&(train['2ndFlrSF']>0)\n",
    "].index).tolist()), 'TtlFloors'] = 2\n",
    "\n",
    "# three floors\n",
    "train.loc[((train[(train['1stFlrSF']>0)&(train['TotalBsmtSF']>0)&(train['2ndFlrSF']>0)\n",
    "].index).tolist()), 'TtlFloors'] = 3\n",
    "\n",
    "# the 2.5 story category\n",
    "train.loc[((train[train['HouseStyle']=='2.5Story'\n",
    "].index).tolist()), 'TtlFloors'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtlFloors\n",
       "2    809\n",
       "3    595\n",
       "1     27\n",
       "4     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check there are no 0s left\n",
    "train['TtlFloors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column \n",
    "test['TtlFloors'] = 0\n",
    "\n",
    "# encode the applicable values\n",
    "# only a ground floor\n",
    "test.loc[((test[(test['1stFlrSF']>0)&(test['TotalBsmtSF']==0)&(test['2ndFlrSF']==0)\n",
    "].index).tolist()), 'TtlFloors'] = 1\n",
    "\n",
    "# ground floor and basement\n",
    "test.loc[((test[(test['1stFlrSF']>0)&(test['TotalBsmtSF']>0)&(test['2ndFlrSF']==0)\n",
    "].index).tolist()), 'TtlFloors'] = 2\n",
    "\n",
    "# ground floor and second floor\n",
    "test.loc[((test[(test['1stFlrSF']>0)&(test['TotalBsmtSF']==0)&(test['2ndFlrSF']>0)\n",
    "].index).tolist()), 'TtlFloors'] = 2\n",
    "\n",
    "# all three floors\n",
    "test.loc[((test[(test['1stFlrSF']>0)&(test['TotalBsmtSF']>0)&(test['2ndFlrSF']>0)\n",
    "].index).tolist()), 'TtlFloors'] = 3\n",
    "\n",
    "# the 2.5 story category\n",
    "test.loc[((test[test['HouseStyle']=='2.5Story'\n",
    "].index).tolist()), 'TtlFloors'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtlFloors\n",
       "2    813\n",
       "3    602\n",
       "1     34\n",
       "4     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check there are no 0s left\n",
    "test['TtlFloors'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
